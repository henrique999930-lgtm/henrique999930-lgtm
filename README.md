<div align="center">
  <h1>Olá, eu sou o Carlos Henrique 👋</h1>
  <p>
    <strong>Engenheiro de Dados</strong> apaixonado por transformar dados brutos em decisões estratégicas e criar soluções escaláveis que geram valor real.<br>
    Experiência prática com pipelines eficientes, automação de ETL, integração de múltiplas fontes e dashboards interativos.
  </p>
  <a href="https://www.linkedin.com/in/carlos-henrique-2a0008378/">
    <img src="https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white" alt="LinkedIn"/>
  </a>
  <a href="mailto:henrique999930@gmail.com">
    <img src="https://img.shields.io/badge/Email-D14836?style=for-the-badge&logo=gmail&logoColor=white" alt="Email"/>
  </a>
</div>

---

### 💻 Habilidades Técnicas

<div align="center">
  <img src="https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white" alt="Python"/>
  <img src="https://img.shields.io/badge/SQL-025E8C?style=for-the-badge&logo=postgresql&logoColor=white" alt="SQL"/>
  <img src="https://img.shields.io/badge/PySpark-E25A1C?style=for-the-badge&logo=apache-spark&logoColor=white" alt="PySpark"/>
  <img src="https://img.shields.io/badge/AWS-232F3E?style=for-the-badge&logo=amazon-aws&logoColor=white" alt="AWS"/>
  <img src="https://img.shields.io/badge/Pandas-150458?style=for-the-badge&logo=pandas&logoColor=white" alt="Pandas"/>
  <img src="https://img.shields.io/badge/PowerBI-F2C811?style=for-the-badge&logo=power-bi&logoColor=black" alt="Power BI"/>
  <img src="https://img.shields.io/badge/Streamlit-FF4B4B?style=for-the-badge&logo=streamlit&logoColor=white" alt="Streamlit"/>
  <img src="https://img.shields.io/badge/Docker-2496ED?style=for-the-badge&logo=docker&logoColor=white" alt="Docker"/>
  <img src="https://img.shields.io/badge/Git-F05032?style=for-the-badge&logo=git&logoColor=white" alt="Git"/>
</div>

---

### 🚀 Meus Principais Projetos

<table>
  <tr>
    <td width="50%">
      <h3>Pipeline de Dados ETL e Dashboard de Vendas</h3>
      <p>Pipeline de ETL completo que extrai dados de vendas de arquivos CSV, os transforma com Python/Pandas e carrega em um Data Warehouse PostgreSQL (Star Schema). O resultado é um dashboard interativo em Streamlit que apresenta métricas e análises visuais.</p>
      <p><strong>Tecnologias:</strong> Python, Pandas, Streamlit, SQL, PostgreSQL.</p>
      <a href="https://github.com/henrique999930-lgtm/pipeline-etl-vendas"><strong>Ver no GitHub &rarr;</strong></a>
    </td>
    <td width="50%">
      <h3>Sales Insight – Dashboard de Vendas Interativo</h3>
      <p>Dashboard desenvolvido com Python e Streamlit para análise de performance de vendas. O projeto integra múltiplas fontes de dados, permitindo a visualização de KPIs e tendências comerciais em tempo real.</p>
      <p><strong>Tecnologias:</strong> Python, Pandas, Streamlit, Power BI.</p>
      <a href="https://github.com/henrique999930-lgtm/sales-insight"><strong>Ver no GitHub &rarr;</strong></a>
    </td>
  </tr>
  <tr>
    <td width="50%">
      <h3>Pipeline ETL para Integração de Dados</h3>
      <p>Pipeline automatizado para extração, transformação e carga de dados de múltiplas fontes. O projeto foi projetado para alta performance e escalabilidade, integrando com serviços da AWS para armazenamento e análise.</p>
      <p><strong>Tecnologias:</strong> Python, PySpark, AWS, SQL.</p>
      <a href="https://github.com/henrique999930-lgtm/Pipeline-etl"><strong>Ver no GitHub &rarr;</strong></a>
    </td>
    <td width="50%">
      <h3>Dashboard de Análise de Dados</h3>
      <p>Aplicação interativa para leitura e análise de arquivos `.csv` com geração automática de gráficos. Ideal para apresentações e insights rápidos, com interface intuitiva e personalizável.</p>
      <p><strong>Tecnologias:</strong> Python, Pandas, Streamlit.</p>
      <a href="https://github.com/henrique999930-lgtm/Dashboard-analise-dados"><strong>Ver no GitHub &rarr;</strong></a>
    </td>
  </tr>
</table>

---

### 🎓 Cursos e Certificações

- **Formação em SQL** – 60h
- **Formação em Python** – 80h
- **Inteligência Artificial** – 50h
- **Engenharia de Dados na AWS** – 40h
- **Machine Learning Avançado** – 60h
